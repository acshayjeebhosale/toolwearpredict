import streamlit as st
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

# -----------------------------
# Load the trained Keras model
# -----------------------------
@st.cache_resource
def load_model():
    return tf.keras.models.load_model("best_milling_model.keras")

model = load_model()

st.title("üõ†Ô∏è Tool Wear Prediction App")
st.write("Enter process parameter values to get predictions from the trained model.")

# -----------------------------
# Define feature ranges (10 features only)
# From your dataset summary (min‚Äìmax values)
# -----------------------------
feature_ranges = {
    "run": (1, 100),                       
    "smcDC": (0.1318359, 9.995117),       
    "vib_spindle": (0.2099609, 0.3759766),
    "case": (1, 50),                      
    "AE_table": (0.012207, 0.355835),     
    "DOC": (0.75, 1.5),                   
    "AE_spindle": (0.007324, 0.4498291),  
    "vib_table": (0.002441, 1.860352),    
    "feed": (0.25, 0.5),                  
    "smcAC": (-4.80957, 4.487305),        
}

# -----------------------------
# Collect user inputs + detect outliers
# -----------------------------
inputs = []
outliers = []
missing_values = []
input_values = {}  # Store values for visualization

for feature, (fmin, fmax) in feature_ranges.items():
    if feature == "run":
        # Integer input for "run" feature
        value = st.number_input(
            f"{feature} (Range: {int(fmin)} to {int(fmax)})",
            value=None,
            placeholder=f"Enter integer between {int(fmin)} and {int(fmax)}",
            step=1,  # Integer steps
            format="%d"  # Display as integer
        )
        # Convert to integer if provided
        if value is not None:
            value = int(value)
    else:
        # Float input for all other features - preserve all entered digits
        value = st.number_input(
            f"{feature} (Range: {fmin} to {fmax})",
            value=None,
            placeholder=f"Enter value between {fmin} and {fmax}",
            format="%f"  # Preserve all decimal places entered by user
        )
    
    # Store the value for visualization
    input_values[feature] = value
    
    # Check if value is provided
    if value is None:
        missing_values.append(feature)
    else:
        # Outlier check only if value is provided
        if value < fmin or value > fmax:
            outliers.append((feature, value, fmin, fmax))
        
        inputs.append(float(value))  # Ensure all values are float for the model

# -----------------------------
# Vibration Spindle Visualization
# -----------------------------
st.subheader("üìä Vibration Spindle Analysis")

# Create sample vibration data based on user input
if input_values["vib_spindle"] is not None:
    vib_value = input_values["vib_spindle"]
    
    # Generate sample vibration waveform
    time = np.linspace(0, 2*np.pi, 100)
    amplitude = vib_value
    vibration_wave = amplitude * np.sin(5 * time) + 0.1 * amplitude * np.random.randn(100)
    
    # Create the plot
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    # Time domain plot
    ax1.plot(time, vibration_wave, 'b-', linewidth=2)
    ax1.set_xlabel('Time')
    ax1.set_ylabel('Amplitude')
    ax1.set_title(f'Time Domain - Vibration Spindle: {vib_value:.6f}')
    ax1.grid(True, alpha=0.3)
    
    # Frequency domain plot (FFT)
    fft_values = np.fft.fft(vibration_wave)
    frequencies = np.fft.fftfreq(len(vibration_wave), time[1]-time[0])
    ax2.plot(frequencies[:50], np.abs(fft_values[:50]), 'r-', linewidth=2)
    ax2.set_xlabel('Frequency (Hz)')
    ax2.set_ylabel('Magnitude')
    ax2.set_title('Frequency Domain (FFT)')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    
    # Display vibration statistics
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Current Vibration", f"{vib_value:.6f}")
    with col2:
        st.metric("Min Expected", f"{feature_ranges['vib_spindle'][0]:.6f}")
    with col3:
        st.metric("Max Expected", f"{feature_ranges['vib_spindle'][1]:.6f}")
else:
    st.info("‚ÑπÔ∏è Enter a vibration spindle value to see the visualization")

# -----------------------------
# NEW: Feature Importance Visualization
# -----------------------------
st.subheader("üìà Feature Importance Analysis")

# Based on dissertation findings (Section 4.1.1: run, smcDC, and vib_spindle were most influential)
feature_importance_data = {
    'Feature': ['run', 'smcDC', 'vib_spindle', 'vib_table', 'AE_table', 
                'AE_spindle', 'smcAC', 'DOC', 'feed', 'case'],
    'Importance': [0.23, 0.19, 0.17, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04, 0.02]
}

importance_df = pd.DataFrame(feature_importance_data)
importance_df = importance_df.sort_values('Importance', ascending=True)

fig_importance, ax_importance = plt.subplots(figsize=(10, 6))
ax_importance.barh(importance_df['Feature'], importance_df['Importance'], 
                   color=['#1f77b4' if x not in ['run', 'smcDC', 'vib_spindle'] else '#ff7f0e' for x in importance_df['Feature']])
ax_importance.set_xlabel('Relative Importance')
ax_importance.set_title('Feature Importance in Tool Wear Prediction')
ax_importance.grid(axis='x', alpha=0.3)

# Highlight the top 3 features as found in the dissertation
ax_importance.text(0.22, 2.2, 'Top 3 Influential Features (Dissertation Finding)', 
                  style='italic', bbox={'facecolor': 'orange', 'alpha': 0.2, 'pad': 5})

st.pyplot(fig_importance)
st.caption("Based on Random Forest feature importance analysis from the dissertation (Section 4.1.1)")

# -----------------------------
# NEW: Material Comparison Visualization
# -----------------------------
st.subheader("üîß Material Comparison Analysis")

# Create a comparison of predicted tool wear for both materials using current inputs
if None not in input_values.values():
    # Create input data for both materials
    input_data_steel = np.array([inputs], dtype=np.float32)
    input_data_cast_iron = np.array([inputs], dtype=np.float32)
    
    # Change material indicator (assuming material is the 4th feature, index 3)
    input_data_steel[0, 3] = 2  # Steel
    input_data_cast_iron[0, 3] = 1  # Cast Iron
    
    # Get predictions
    prediction_steel = model.predict(input_data_steel)[0][0]
    prediction_cast_iron = model.predict(input_data_cast_iron)[0][0]
    
    # Create comparison chart
    materials = ['Cast Iron', 'Steel']
    predictions = [prediction_cast_iron, prediction_steel]
    colors = ['#1f77b4', '#ff7f0e']
    
    fig_material, ax_material = plt.subplots(figsize=(8, 6))
    bars = ax_material.bar(materials, predictions, color=colors, alpha=0.7)
    ax_material.set_ylabel('Predicted Tool Wear')
    ax_material.set_title('Predicted Tool Wear by Material Type')
    ax_material.grid(axis='y', alpha=0.3)
    
    # Add value labels on bars
    for i, v in enumerate(predictions):
        ax_material.text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom')
    
    st.pyplot(fig_material)
    st.info("""
    ‚ÑπÔ∏è Based on dissertation findings (Section 3.2): 
    - Cast iron (65.4% of dataset) typically generates higher vibration
    - Steel (34.6% of dataset) may result in more consistent but potentially higher tool wear rates
    """)
else:
    st.info("‚ÑπÔ∏è Enter all parameter values to see material comparison analysis")

# -----------------------------
# Prediction
# -----------------------------
if st.button("Predict"):
    # Check if all values are provided
    if missing_values:
        st.error(f"‚ùå Please provide values for: {', '.join(missing_values)}")
    else:
        # Convert to numpy array
        input_data = np.array([inputs], dtype=np.float32)
        
        if outliers:
            for feat, val, fmin, fmax in outliers:
                st.warning(
                    f"‚ö†Ô∏è {feat} = {val} is **outside the expected range** "
                    f"({fmin} to {fmax}). This feature may be an **outlier** "
                    f"and should be examined or monitored again."
                )
        
        # Run prediction
        prediction = model.predict(input_data)
        
        # Round only the predicted value to 6 decimal places
        rounded_prediction = round(prediction[0][0], 6)
        
        st.success(f"‚úÖ Predicted Tool Wear: {rounded_prediction:.6f} units")
        
        # Context from dissertation
        st.info("""
        **Dissertation Context:** This prediction is generated by a Deep Neural Network that 
        achieved R¬≤ = 0.972, significantly outperforming the Random Forest baseline (R¬≤ = 0.789) 
        as detailed in Section 4.1.3 of the dissertation.
        """)
        
        # Interpretation guidance based on dissertation
        if rounded_prediction > 0.7:
            st.error("""
            üö® **High Tool Wear Alert:** Based on the EOL criteria established in Section 3.2.9 
            of the dissertation, this level of tool wear may indicate approaching End-of-Life conditions.
            """)
        elif rounded_prediction > 0.4:
            st.warning("""
            ‚ö†Ô∏è **Moderate Tool Wear:** Tool is wearing but remains within operational limits. 
            Monitor vibration signals as established in the literature review.
            """)
        else:
            st.success("""
            ‚úÖ **Low Tool Wear:** Tool is in good condition with minimal wear.
            """)

st.info("‚ÑπÔ∏è Note: Predictions with outlier inputs may be unreliable.")
